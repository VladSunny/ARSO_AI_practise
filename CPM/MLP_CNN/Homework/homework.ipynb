{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a7bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Фиксируем seed для воспроизводимости\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(42)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0742e19",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "В этом задании вам нужно будет подобрать архитектуру нейронной сети, чтобы пробить порог в 80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ВАША АРХИТЕКТУРА (TODO)\n",
    "# ==========================================\n",
    "\n",
    "class MySuperCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MySuperCNN, self).__init__()\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # TODO: Определите слои вашей модели здесь\n",
    "        # Подсказка: Используйте nn.Sequential, nn.Conv2d, nn.BatchNorm2d, nn.ReLU, nn.MaxPool2d\n",
    "        # Пример: \n",
    "        # self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        # ------------------------------------------------------------------\n",
    "        \n",
    "        pass \n",
    "\n",
    "    def forward(self, x):\n",
    "        # ------------------------------------------------------------------\n",
    "        # TODO: Опишите прямой проход\n",
    "        # Не забудьте про flatten перед полносвязными слоями: x = x.view(x.size(0), -1)\n",
    "        # ------------------------------------------------------------------\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySuperCNN().to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Количество параметров: {num_params:,}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs=10):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Валидация в конце эпохи\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(trainloader):.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "\n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10055c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc = train_loop(model, epochs=10) \n",
    "\n",
    "print(f\"\\nИтоговая точность: {final_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка результата\n",
    "assert final_acc > 80.0, \"Точность ниже 80%. Попробуйте добавить слоев, BatchNorm или увеличить ширину сети!\"\n",
    "print(\"Отличная работа! Тест пройден.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d91a1f",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FixedCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 16x16\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 8x8\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Настройки обучения\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Фиксированная статистика нормализации для CIFAR-10\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для запуска эксперимента\n",
    "def run_experiment(name, train_transform, epochs=10):\n",
    "    print(f\"\\n=== Запуск эксперимента: {name} ===\")\n",
    "    \n",
    "    # Тестовый трансформ всегда фиксирован (только нормализация)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*stats)\n",
    "    ])\n",
    "    \n",
    "    # Загрузка данных\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Реинициализация модели\n",
    "    model = FixedCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "    return train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcf7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАЙТЕ ТРИ СТРАТЕГИИ АУГМЕНТАЦИИ\n",
    "\n",
    "# Стратегия 1: Baseline (ТолькоToTensor + Normalize). Должен быть сильный переобуч.\n",
    "transforms_baseline = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# Стратегия 2: \"Вредные\" аугментации. \n",
    "# Попробуйте то, что ломает семантику (RandomVerticalFlip, слишком сильный Jitter, Invert и т.д.)\n",
    "transforms_bad = transforms.Compose([\n",
    "    # TODO: Добавьте сюда плохие аугментации\n",
    "    transforms.RandomVerticalFlip(p=1.0), # Пример: переворачиваем машины вверх колесами\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# Стратегия 3: \"Идеальные\" аугментации.\n",
    "# Попробуйте RandomHorizontalFlip, RandomSizedCrop, RandomRotation и т.д.\n",
    "transforms_best = transforms.Compose([\n",
    "    # TODO: Добавьте сюда хорошие аугментации\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # ...\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1994ac",
   "metadata": {},
   "source": [
    "## ВИЗУАЛИЗАЦИЯ (Обязательно посмотрите, что вы скармливаете сети!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb31b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_aug(transform, title):\n",
    "    # Берем чистую картинку\n",
    "    raw_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "    img = raw_set.data[0] # Картинка numpy array\n",
    "    img_pil = transforms.ToPILImage()(img)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i in range(5):\n",
    "        # Применяем трансформ (нужно убрать Normalize для визуализации, чтобы цвета не поплыли)\n",
    "        # Это хак для визуализации, в реальном обучении Normalize нужен\n",
    "        aug_img = transform(img_pil)\n",
    "        \n",
    "        # Если трансформ вернул Tensor, переводим обратно для показа\n",
    "        if isinstance(aug_img, torch.Tensor):\n",
    "             # Denormalize вручную для показа, если там был Normalize\n",
    "             aug_img = aug_img.permute(1, 2, 0).numpy()\n",
    "             aug_img = (aug_img * stats[1]) + stats[0] # un-normalize\n",
    "             aug_img = np.clip(aug_img, 0, 1)\n",
    "             \n",
    "        axes[i].imshow(aug_img)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Эта функция покажет, как transforms_best меняют одну и ту же лягушку\n",
    "# (Уберите нормализацию из transforms_best временно или создайте копию для визуализации без неё)\n",
    "# show_aug(transforms_best, \"My Best Augmentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Запуск Baseline\n",
    "train_base, val_base = run_experiment(\"Baseline (No Augs)\", transforms_baseline, epochs=10)\n",
    "\n",
    "# 2. Запуск Bad\n",
    "train_bad, val_bad = run_experiment(\"Bad Augmentations\", transforms_bad, epochs=10)\n",
    "\n",
    "# 3. Запуск Best\n",
    "train_best, val_best = run_experiment(\"Best Augmentations\", transforms_best, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee198f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_base, label='Baseline Val', linestyle='--')\n",
    "plt.plot(val_bad, label='Bad Augs Val', linestyle=':')\n",
    "plt.plot(val_best, label='Best Augs Val', linewidth=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Битва Аугментаций: Валидация')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Best Val Acc: {val_best[-1]:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
