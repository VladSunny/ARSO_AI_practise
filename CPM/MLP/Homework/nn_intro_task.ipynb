{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание: улучши нейросеть**\n",
    "\n",
    "Сборная Москвы по ИИ | Введение в нейронные сети\n",
    "\n",
    "---\n",
    "\n",
    "В основном ноутбуке мы обучили простую полносвязную сеть на FashionMNIST и получили ~87% accuracy.\n",
    "\n",
    "Твоя задача — улучшить модель. Вот несколько идей:\n",
    "\n",
    "1. **Добавь больше слоёв** — сделай сеть глубже (например, 4-5 линейных слоёв с ReLU)\n",
    "2. **Поменяй размеры слоёв** — попробуй больше/меньше нейронов (128, 512, ...)\n",
    "3. **Добавь Dropout** — `nn.Dropout(p=0.2)` между слоями для регуляризации\n",
    "4. **Поменяй оптимизатор / lr** — попробуй SGD с momentum, или другой learning rate\n",
    "5. **Обучи дольше** — увеличь число эпох\n",
    "\n",
    "Цель: попробуй достичь **> 90%** accuracy на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных** (такая же, как в основном ноутбуке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60000, Test: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=16)\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функции для обучения и оценки** (такие же, как в основном ноутбуке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Базовая модель (для сравнения)**\n",
    "\n",
    "Это та же модель из основного ноутбука. Запусти её, чтобы получить baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# baseline = SimpleNet().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(baseline.parameters(), lr=1e-3)\n",
    "\n",
    "# print('Обучаем baseline...')\n",
    "# for epoch in range(10):\n",
    "#     train_loss, train_acc = train_epoch(baseline, train_loader, criterion, optimizer, device)\n",
    "#     test_loss, test_acc = evaluate(baseline, test_loader, criterion, device)\n",
    "#     print(f'Epoch {epoch+1:2d}/10 | Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f}')\n",
    "\n",
    "# print(f'\\nBaseline Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Твоя модель**\n",
    "\n",
    "Напиши свою улучшенную модель ниже. Не забудь:\n",
    "- Наследоваться от `nn.Module`\n",
    "- Определить `__init__` и `forward`\n",
    "- Входной размер: `28 * 28 = 784` (после Flatten)\n",
    "- Выходной размер: `10` классов (логиты, без softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout=0.3):\n",
    "        super(ImprovedNet, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Flatten()\n",
    "        ]\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров: 245,482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1221b386a594ef2a47515d0a46c4d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 | Train Loss: 0.3428 LR: 0.0050 | Val Loss (LogLoss): 0.3472 Acc: 0.8811\n",
      "Epoch  20 | Train Loss: 0.2692 LR: 0.0040 | Val Loss (LogLoss): 0.3197 Acc: 0.8887\n",
      "Epoch  30 | Train Loss: 0.2237 LR: 0.0032 | Val Loss (LogLoss): 0.3150 Acc: 0.8980\n",
      "Epoch  40 | Train Loss: 0.1874 LR: 0.0026 | Val Loss (LogLoss): 0.3221 Acc: 0.9012\n",
      "Epoch  50 | Train Loss: 0.1652 LR: 0.0020 | Val Loss (LogLoss): 0.3413 Acc: 0.9006\n",
      "Early stopping на эпохе 55 (val_loss не уменьшался)\n",
      "\n",
      "Лучший результат (min val_loss): 0.3110\n"
     ]
    }
   ],
   "source": [
    "my_model = ImprovedNet(input_dim=28*28, hidden_dims=[256, 128, 64, 32], output_dim=10).to(device)\n",
    "my_criterion = nn.CrossEntropyLoss()\n",
    "my_optimizer = torch.optim.Adam(my_model.parameters(), lr=0.005)\n",
    "my_scheduler = StepLR(my_optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "print(f'Параметров: {sum(p.numel() for p in my_model.parameters()):,}')\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses_w, val_losses_w = [], []\n",
    "train_accs_w, val_accs_w = [], []\n",
    "best_val_loss = float('inf')\n",
    "patience_w, counter_w = 30, 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    my_model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        logits = my_model(X_batch)\n",
    "        loss = my_criterion(logits, y_batch)\n",
    "        my_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        train_correct += (preds == y_batch).sum().item()\n",
    "        train_total += y_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    train_losses_w.append(train_loss)\n",
    "    train_accs_w.append(train_acc)\n",
    "\n",
    "    my_model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = my_model(X_batch)\n",
    "            \n",
    "            loss = my_criterion(logits, y_batch)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses_w.append(val_loss)\n",
    "    val_accs_w.append(val_acc)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter_w = 0\n",
    "        torch.save(my_model.state_dict(), './models/best_model.pth')\n",
    "    else:\n",
    "        counter_w += 1\n",
    "        if counter_w >= patience_w:\n",
    "            print(f\"Early stopping на эпохе {epoch+1} (val_loss не уменьшался)\")\n",
    "            break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} LR: {my_scheduler.get_last_lr()[0]:.4f} | \"\n",
    "              f\"Val Loss (LogLoss): {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    my_scheduler.step()\n",
    "\n",
    "print(f\"\\nЛучший результат (min val_loss): {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тесте: 0.9042\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = evaluate(my_model, test_loader, my_criterion, device)\n",
    "print(f'Точность на тесте: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравнение результатов**\n",
    "\n",
    "После обучения сравни accuracy своей модели с baseline (~87%). Удалось ли побить 89%?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arso-ai-practise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
