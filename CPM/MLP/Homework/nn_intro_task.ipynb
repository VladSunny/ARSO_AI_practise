{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание: улучши нейросеть**\n",
    "\n",
    "Сборная Москвы по ИИ | Введение в нейронные сети\n",
    "\n",
    "---\n",
    "\n",
    "В основном ноутбуке мы обучили простую полносвязную сеть на FashionMNIST и получили ~87% accuracy.\n",
    "\n",
    "Твоя задача — улучшить модель. Вот несколько идей:\n",
    "\n",
    "1. **Добавь больше слоёв** — сделай сеть глубже (например, 4-5 линейных слоёв с ReLU)\n",
    "2. **Поменяй размеры слоёв** — попробуй больше/меньше нейронов (128, 512, ...)\n",
    "3. **Добавь Dropout** — `nn.Dropout(p=0.2)` между слоями для регуляризации\n",
    "4. **Поменяй оптимизатор / lr** — попробуй SGD с momentum, или другой learning rate\n",
    "5. **Обучи дольше** — увеличь число эпох\n",
    "\n",
    "Цель: попробуй достичь **> 90%** accuracy на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных** (такая же, как в основном ноутбуке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.datasets' has no attribute 'FashionMNIST'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m transform = transforms.Compose([\n\u001b[32m      2\u001b[39m     transforms.ToTensor(),\n\u001b[32m      3\u001b[39m     transforms.Normalize((\u001b[32m0.5\u001b[39m,), (\u001b[32m0.5\u001b[39m,))\n\u001b[32m      4\u001b[39m ])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_dataset = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFashionMNIST\u001b[49m(\n\u001b[32m      7\u001b[39m     root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m test_dataset = torchvision.datasets.FashionMNIST(\n\u001b[32m     10\u001b[39m     root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mFalse\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m train_loader = DataLoader(train_dataset, batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torchvision.datasets' has no attribute 'FashionMNIST'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функции для обучения и оценки** (такие же, как в основном ноутбуке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Базовая модель (для сравнения)**\n",
    "\n",
    "Это та же модель из основного ноутбука. Запусти её, чтобы получить baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем baseline...\n",
      "Epoch  1/10 | Train acc: 0.8184 | Test acc: 0.8391\n",
      "Epoch  2/10 | Train acc: 0.8618 | Test acc: 0.8521\n",
      "Epoch  3/10 | Train acc: 0.8768 | Test acc: 0.8588\n",
      "Epoch  4/10 | Train acc: 0.8854 | Test acc: 0.8527\n",
      "Epoch  5/10 | Train acc: 0.8913 | Test acc: 0.8669\n",
      "Epoch  6/10 | Train acc: 0.8979 | Test acc: 0.8795\n",
      "Epoch  7/10 | Train acc: 0.9016 | Test acc: 0.8770\n",
      "Epoch  8/10 | Train acc: 0.9079 | Test acc: 0.8830\n",
      "Epoch  9/10 | Train acc: 0.9100 | Test acc: 0.8859\n",
      "Epoch 10/10 | Train acc: 0.9144 | Test acc: 0.8819\n",
      "\n",
      "Baseline Test accuracy: 0.8819\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "baseline = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(baseline.parameters(), lr=1e-3)\n",
    "\n",
    "print('Обучаем baseline...')\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_epoch(baseline, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(baseline, test_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1:2d}/10 | Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nBaseline Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Твоя модель**\n",
    "\n",
    "Напиши свою улучшенную модель ниже. Не забудь:\n",
    "- Наследоваться от `nn.Module`\n",
    "- Определить `__init__` и `forward`\n",
    "- Входной размер: `28 * 28 = 784` (после Flatten)\n",
    "- Выходной размер: `10` классов (логиты, без softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # TODO: определи слои\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: определи forward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение твоей модели\n",
    "\n",
    "# my_model = ImprovedNet(num_classes=10).to(device)\n",
    "# my_criterion = nn.CrossEntropyLoss()\n",
    "# my_optimizer = torch.optim.Adam(my_model.parameters(), lr=1e-3)\n",
    "\n",
    "# print(f'Параметров: {sum(p.numel() for p in my_model.parameters()):,}')\n",
    "\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, train_acc = train_epoch(my_model, train_loader, my_criterion, my_optimizer, device)\n",
    "#     test_loss, test_acc = evaluate(my_model, test_loader, my_criterion, device)\n",
    "#     print(f'Epoch {epoch+1:2d}/{num_epochs} | '\n",
    "#           f'Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | '\n",
    "#           f'Test loss: {test_loss:.4f}, acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравнение результатов**\n",
    "\n",
    "После обучения сравни accuracy своей модели с baseline (~87%). Удалось ли побить 89%?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arso-ai-practise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
